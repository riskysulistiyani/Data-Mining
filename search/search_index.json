{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Di Halaman Tugas Data Mining \u00b6 Biodata \u00b6 `Nama : Risky Sulistiyani. `NIM : 180411100036. `Kelas : Penambangan Data 5D. `Angkatan : 2018. Dosen Pengampu : Mula'ab,S.si.,M.Kom Alamat : Jakarta","title":"index"},{"location":"#welcome-di-halaman-tugas-data-mining","text":"","title":"Welcome Di Halaman Tugas Data Mining"},{"location":"#biodata","text":"`Nama : Risky Sulistiyani. `NIM : 180411100036. `Kelas : Penambangan Data 5D. `Angkatan : 2018. Dosen Pengampu : Mula'ab,S.si.,M.Kom Alamat : Jakarta","title":"Biodata"},{"location":"Tugas 1/","text":"Memahami Data \u00b6 Statistik Deskriptif \u00b6 Statistik deskriptif adalah metode dari pengorganisasian, penjumlahan, dan penyajian data dalam sebuah cara yang nyaman dan informatif, termasuk teknik grafik, dan teknik penghitungan. Pada sesi tulisan ini teknik grafik tidak akan dibahas, penyajian teknik ini akan dijelaskan pada sesi tulisan yang lain. Statistik deskriptif dapat mendeskripsikan data yang sedang dianalisis, tetapi tidak boleh menarik kesimpulan apapun dari data. Untuk pengambilan keputusan, kita perlukan cabang dari ilmu statistik lainnya yaitu statistik inferensia. Statistik inferensia akan dijelaskan pada sesi tulisan yang lain Ukuran-ukuran statistik deskriptif Ukuran statistik deskriptif dapat digolongkan menjadi dua kelompok, yaitu ukuran nilai tengah dan ukuran deviasi. Ukuran nilai tengah terdiri dari rata-rata ( mean ), median, dan modus. Sedangkan ukuran deviasi terdiri dari varians, simpangan baku, koefisien variasi, dan nilai jarak ( range ). Ukuran-ukuran statistik deskriptif tersebut akan dijelaskan penggunaannya baik untuk data tunggal maupun data berkelompok. Ukuran nilai tengah Rata-rata (Mean) Rata-rata ditulis dengan menggunakan simbol \u03bc (dibaca:\u201dmiu\u201d) untuk menyatakan rata-rata populasi, dan (dibaca: x bar) untuk menyatakan rata-rata sampel. Secara aljabar rata-rata dapat ditulis sebagai berikut: \u200b untuk rata-rata populasi \u200b \u200b dimana N adalah banyaknya populasi \u200b untuk rata-rata sampel \u200b \u200b dimana n adalah banyaknya sampel contoh: Dari 11 pohon pear menghasilkan buah dengan berat sbb (dlm Kg): 330 284 326 268 236 346 326 402 374 292 380 Hitunglah rata-rata produksi 11 pohon pear ? Jadi rata-rata produksi dari 11 pohon pear adalah 324 Kg. Rata-rata untuk data berkelompok . Apabila data sudah disajikan dalam data berkelompok seperti dalam bentuk tabel frekuensi dimana observasi-observasi dikelompokan kedalam kelas-kelas yang disebut frekuensi, maka rumus rata-ratanya adalah sebagai berikut: \u200b Contoh: Hitunglah rata-rata nilai statistik dari 50 mahasiswa pada Table 1 dibawah ini. \u200b \u200b Jadi perkiraan rata-rata nilai statistik 50 mahasiswa adalah 65,7. Median Ukuran nilai tengah lainnya yang mungkin dapat merupakan pilihan selain rata-rata adalah median. Jika data pada contoh produksi buah pear diurutkan dari nilai terkecil hingga ke nilai terbesar, maka nilai tengahnya adalah 326 kg artinya lima pohon pear mempunyai produksi dibawahnya dan lima pohon pear mempunyai produksi diatasnya. Nilai tengah inilah yang dikatakan median . Penentuan median bisa langsung didapat jika jumlah observasinya adalah ganjil, namun jika jumlah observasinya adalah genap maka akan didapat dua nilai tengah. Dalam situasi demikian, untuk mendapatkan mediannya yaitu dengan merata-ratakan dua nilai tengah yang didapat. Prosedur untuk mendapatkan median yaitu harus mengurutkan data dari yang terkecil hingga yang terbesar terlebih dahulu sebelum mengambil nilai tengahnya. Dengan kata lain median adalah data yang ke . Median untuk data berkelompok Untuk data yang sudah dikelompokkan dan disajikan dalam tabel frekuensi, maka mediannya dapat dicari dengan rumus sebagai berikut: Kelas median adalah kelas dimana terdapat nilai median di dalamnya. Untuk menentukan kelas median bagilah seluruh observasi dengan dua artinya 50 % dari seluruh observasi terletak sebelum median dan 50 % lainnya terletak sesudahnya. Jika kita lihat tabel frekuensi (Tabel 1) maka mediannya merupakan observasi yang ke (50/2) yaitu yang ke 25. Jumlah tiga frekuensi pertama ( f1 + f2 + f3 ) yaitu 3 + 5 + 8 = 16. Untuk mencapai 25 observasi diperlukan 9 observasi lagi. 9 observasi tersebut dapat dipenuhi dari frekuensi keempat ( f4 ) karena jumlah observasi f4 ada sebanyak 14 observasi. Jadi median terletak pada kelas keempat atau kelas (60 \u2013 69) dengan kata lain kelas keempat adalah kelas median. contoh: Hitunglah nilai median dari data kelompok pada Tabel 1. solusi: \u200b Jadi mediannya, \u200b Pertanyaan yang mungkin timbul adalah jika kita punya data aslinya, apakah nilai median yang sebenarnya adalah 66,33? jawabannya belum tentu, karena cara ini adalah cara interpolasi dimana data aslinya memang tidak diketahui, yang ada adalah data sudah dalam bentuk tabel frekuensi atau sudah dikelompokkan. Walaupun hasil interpolasi ini mungkin tidak tepat, namun cara ini memberikan hasil yang mendekati nilai median yang sebenarnya. Modus Modus dari suatu kelompok observasi adalah nilai observasi yang mempunyai frekuensi pemunculan paling banyak atau dengan kata lain yaitu nilai yang paling banyak muncul. Konsep dari modus ini berhubungan dengan kemunculan yang berulang-ulang dari suatu nilai observasi. Contoh: jika kita gunakan data produksi 11 pohon pear, maka modus produksinya adalah 326 kg. Dalam kegiatan sehari-hari, modus adalah ukuran nilai tengah yang paling jarang digunakan dibanding rata-rata atau median. Modus mungkin lebih sering digunakan pada data yang mempunyai banyak variasi dalam ukurannya, itupun untuk jumlah data yang besar. Sebagai contoh modus dari ukuran barang yang terjual sering digunakan untuk mengetahui barang yang paling disenangi konsumen. Suatu distribusi atau kelompok data mungkin tidak mempunyai modus atau mungkin mempunyai modus lebih dari satu. Distribusi yang mempunyai satu modus disebut Unimodus, yang mempunyai dua modus disebut Bimodus dan yang mempunyai modus lebih dari dua disebut Multimodus. contoh: Tentukan modus dari data dibawah ini, jika ada tentukan nilainya. a). 2, 3, 5, 7, 8. b). 2, 5, 7, 9, 9, 9, 10, 10, 11, 12. c). 2, 3, 4, 4, 4, 5, 5, 7, 7, 7, 9. solusi: Data a) tidak mempunyai modus karena semua nilai mempunyai frekuensi yang sama. Data b) mempunyai modus = 9, karena nilai observasi ini mempunyai frekuensi paling banyak. Data c) mempunyai dua modus yaitu 4 dan 7, dua nilai observasi tersebut mempunyai frekuensi palingbanyak dan sama banyak. Modus untuk data berkelompok Apabila data sudah dikelompokkan dan disajikan dalam tabel frekuensi, maka modusnya mempunyai rumus sebagai berikut: \u200b Kelas modus adalah kelas dimana terdapat nilai modus di dalamnya. Contoh: Hitunglah nilai modus dari data kelompok pada Tabel 1. solusi: Kelas modus adalah kelompok (60 \u2013 69), karena kelompok ini mempunyai frekuensi paling banyak. \u200b Ukuran dispersi Varians Dengan ukuran nilai tengah saja kita tidak akan pernah cukup untuk memberikan ringkasan karakteristik dari sebuah set data. Bagaimana sebaran observari dari nilai rata-ratanya? Apakah observasi mempunyai dispersi atau penyimpangan yang besar dari rata-ratanya? Kita biasanya memerlukan ukuran lainnya yaitu suatu ukuran tentang dispersi atau variasi didalam data. Pada kenyataannya nilai-nilai observasi suatu populasi ada yang lebih besar dari rata-rata dan ada yang lebih kecil dari rata. Informasi ini yang biasanya merupakan keterangan tambahan mengenai karakteristik dari satu set data yaitu informasi mengenai jumlah penyimpangan dalam data. Biasanya kita tertarik dengan penyimpangan nilai-nilai observasi dalam data terhadap rata-ratanya yaitu selisihnya. Rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan yang biasa disebut dengan varians dari observasi. Simbol varians pada ukuran populasi adalah (dibaca: sigma kuadrat) dan pada ukuran sampel adalah s 2 . Simpangan baku Akar dari varians dinamakan standar deviasi atau simpangan baku. Standar deviasi merupakan ukuran simpangan yang sering digunakan dalam analisa. Nilai standar deviasi pada dasarnya menggambarkan besaran sebaran suatu kelompok data terhadap rata-ratanya atau dengan kata lain gambaran keheterogenan suatu kelompok data. Formula standar deviasi adalah sebagai berikut: \u200b Contoh: jika kita gunakan data produksi 11 pohon pear, maka varians produksinya adalah: Dari hasil perhitungan didapat varians produksi dari 11 pohon pear adalah sebesar 2.575,2 kg. sehingga standar deviasi produksinya adalah sebesar 50,75 kg. katakan kita mempunyai data produksi (dalam kg) sebanyak 10 pohon pear dengan jenis yang berbeda dengan kelompok 11 pohon pear sebelumnya, yaitu: 230 475 366 268 136 330 326 402 215 492 kelompok ini mempunyai nilai rata-rata yang sama dengan kelompok 11 pohon pear sebelumnya yaitu sebasar 324 kg. Apakah dua kelompok pohon pear tersebut mempunyai kemampuan produksi yang sama? atau dengan kata lain kelompok pohon pear mana yang lebih konsisten dalam berproduksi? Jika harus memilih jenis pohon pear mana yang lebih konsisten berproduksi, maka kita akan memilih pohon pear pada kelompok yang mempunyai nilai varians terkecil (kelompok yang lebih homogen). Varians untuk data berkelompok Formula varians untuk data berkelompok adalah sebagai berikut: \u200b contoh: kita gunakan data nilai statistik 50 mahasiswa. Koefisien variasi Standar deviasi dapat mengukur keheterogenan atau variasi suatu kelompok data. Namun jika kita ingin membandingkan dua kelompok data yang mempunyai ukuran yang berbeda, standar deviasi tidak dapat digunakan artinya standar deviasi yang lebih besar tidak selalu berarti kelompok data tersebut lebih heterogen Untuk keperluan perbandingan dua kelompok data tanpa melihat ukuran satuannya, maka dapat digunakan suatu ukuran variasi yang dinamakan koefisien variasi (CV). Rumus CV dituliskan sebagai berikut: \u200b Jika CV1 > CV2 berarti kelompok data pertama lebih bervariasi atau lebih heterogen dari pada kelompok kedua. Ukuran nilai jarak (Range) Ukuran dispersi yang paling sederhana pada suatu data numerik mungkin dengan cara menghitung selisih nilai terbesar (nilai maksimum) dengan nilai terkecil (nilai minimum). Cara ini dikenal dengan sebutan Range . Range = Nilai maksimum \u2013 Nilai minimum. Range produksi 11 pohon pear = 402 \u2013 306 = 96 Ukuran Range untuk data berkelompok Untuk data berkelompok, nilai range dihitung berdasarkan selisih antara nilai tengah kelas terakhir dengan nilai tengah pertama atau selisih batas atas kelas terakhir dengan batas bawah kelas pertama. Range = Nilai tengah kelas terakhir \u2013 Nilai tengah kelas pertama. atau Range = Bonderi atas kelas terakhir \u2013 Bonderi bawah kelas pertama. dari data nilai statistik 50 mahasiswa pada tabel 1, nilai range nya adalah: Range = 94,5 \u2013 34,5 = 60 (cara ini cenderung menghilangkan nilai ekstrim). atau Range = 99,5 \u2013 29,5 = 70. Contoh Program \u00b6 File tambahannya lihat disini import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () Pustaka \u00b6 https://digensia.wordpress.com/2012/03/15/statistik-deskriptif/","title":"statistik deskriptif"},{"location":"Tugas 1/#memahami-data","text":"","title":"Memahami Data"},{"location":"Tugas 1/#statistik-deskriptif","text":"Statistik deskriptif adalah metode dari pengorganisasian, penjumlahan, dan penyajian data dalam sebuah cara yang nyaman dan informatif, termasuk teknik grafik, dan teknik penghitungan. Pada sesi tulisan ini teknik grafik tidak akan dibahas, penyajian teknik ini akan dijelaskan pada sesi tulisan yang lain. Statistik deskriptif dapat mendeskripsikan data yang sedang dianalisis, tetapi tidak boleh menarik kesimpulan apapun dari data. Untuk pengambilan keputusan, kita perlukan cabang dari ilmu statistik lainnya yaitu statistik inferensia. Statistik inferensia akan dijelaskan pada sesi tulisan yang lain Ukuran-ukuran statistik deskriptif Ukuran statistik deskriptif dapat digolongkan menjadi dua kelompok, yaitu ukuran nilai tengah dan ukuran deviasi. Ukuran nilai tengah terdiri dari rata-rata ( mean ), median, dan modus. Sedangkan ukuran deviasi terdiri dari varians, simpangan baku, koefisien variasi, dan nilai jarak ( range ). Ukuran-ukuran statistik deskriptif tersebut akan dijelaskan penggunaannya baik untuk data tunggal maupun data berkelompok. Ukuran nilai tengah Rata-rata (Mean) Rata-rata ditulis dengan menggunakan simbol \u03bc (dibaca:\u201dmiu\u201d) untuk menyatakan rata-rata populasi, dan (dibaca: x bar) untuk menyatakan rata-rata sampel. Secara aljabar rata-rata dapat ditulis sebagai berikut: \u200b untuk rata-rata populasi \u200b \u200b dimana N adalah banyaknya populasi \u200b untuk rata-rata sampel \u200b \u200b dimana n adalah banyaknya sampel contoh: Dari 11 pohon pear menghasilkan buah dengan berat sbb (dlm Kg): 330 284 326 268 236 346 326 402 374 292 380 Hitunglah rata-rata produksi 11 pohon pear ? Jadi rata-rata produksi dari 11 pohon pear adalah 324 Kg. Rata-rata untuk data berkelompok . Apabila data sudah disajikan dalam data berkelompok seperti dalam bentuk tabel frekuensi dimana observasi-observasi dikelompokan kedalam kelas-kelas yang disebut frekuensi, maka rumus rata-ratanya adalah sebagai berikut: \u200b Contoh: Hitunglah rata-rata nilai statistik dari 50 mahasiswa pada Table 1 dibawah ini. \u200b \u200b Jadi perkiraan rata-rata nilai statistik 50 mahasiswa adalah 65,7. Median Ukuran nilai tengah lainnya yang mungkin dapat merupakan pilihan selain rata-rata adalah median. Jika data pada contoh produksi buah pear diurutkan dari nilai terkecil hingga ke nilai terbesar, maka nilai tengahnya adalah 326 kg artinya lima pohon pear mempunyai produksi dibawahnya dan lima pohon pear mempunyai produksi diatasnya. Nilai tengah inilah yang dikatakan median . Penentuan median bisa langsung didapat jika jumlah observasinya adalah ganjil, namun jika jumlah observasinya adalah genap maka akan didapat dua nilai tengah. Dalam situasi demikian, untuk mendapatkan mediannya yaitu dengan merata-ratakan dua nilai tengah yang didapat. Prosedur untuk mendapatkan median yaitu harus mengurutkan data dari yang terkecil hingga yang terbesar terlebih dahulu sebelum mengambil nilai tengahnya. Dengan kata lain median adalah data yang ke . Median untuk data berkelompok Untuk data yang sudah dikelompokkan dan disajikan dalam tabel frekuensi, maka mediannya dapat dicari dengan rumus sebagai berikut: Kelas median adalah kelas dimana terdapat nilai median di dalamnya. Untuk menentukan kelas median bagilah seluruh observasi dengan dua artinya 50 % dari seluruh observasi terletak sebelum median dan 50 % lainnya terletak sesudahnya. Jika kita lihat tabel frekuensi (Tabel 1) maka mediannya merupakan observasi yang ke (50/2) yaitu yang ke 25. Jumlah tiga frekuensi pertama ( f1 + f2 + f3 ) yaitu 3 + 5 + 8 = 16. Untuk mencapai 25 observasi diperlukan 9 observasi lagi. 9 observasi tersebut dapat dipenuhi dari frekuensi keempat ( f4 ) karena jumlah observasi f4 ada sebanyak 14 observasi. Jadi median terletak pada kelas keempat atau kelas (60 \u2013 69) dengan kata lain kelas keempat adalah kelas median. contoh: Hitunglah nilai median dari data kelompok pada Tabel 1. solusi: \u200b Jadi mediannya, \u200b Pertanyaan yang mungkin timbul adalah jika kita punya data aslinya, apakah nilai median yang sebenarnya adalah 66,33? jawabannya belum tentu, karena cara ini adalah cara interpolasi dimana data aslinya memang tidak diketahui, yang ada adalah data sudah dalam bentuk tabel frekuensi atau sudah dikelompokkan. Walaupun hasil interpolasi ini mungkin tidak tepat, namun cara ini memberikan hasil yang mendekati nilai median yang sebenarnya. Modus Modus dari suatu kelompok observasi adalah nilai observasi yang mempunyai frekuensi pemunculan paling banyak atau dengan kata lain yaitu nilai yang paling banyak muncul. Konsep dari modus ini berhubungan dengan kemunculan yang berulang-ulang dari suatu nilai observasi. Contoh: jika kita gunakan data produksi 11 pohon pear, maka modus produksinya adalah 326 kg. Dalam kegiatan sehari-hari, modus adalah ukuran nilai tengah yang paling jarang digunakan dibanding rata-rata atau median. Modus mungkin lebih sering digunakan pada data yang mempunyai banyak variasi dalam ukurannya, itupun untuk jumlah data yang besar. Sebagai contoh modus dari ukuran barang yang terjual sering digunakan untuk mengetahui barang yang paling disenangi konsumen. Suatu distribusi atau kelompok data mungkin tidak mempunyai modus atau mungkin mempunyai modus lebih dari satu. Distribusi yang mempunyai satu modus disebut Unimodus, yang mempunyai dua modus disebut Bimodus dan yang mempunyai modus lebih dari dua disebut Multimodus. contoh: Tentukan modus dari data dibawah ini, jika ada tentukan nilainya. a). 2, 3, 5, 7, 8. b). 2, 5, 7, 9, 9, 9, 10, 10, 11, 12. c). 2, 3, 4, 4, 4, 5, 5, 7, 7, 7, 9. solusi: Data a) tidak mempunyai modus karena semua nilai mempunyai frekuensi yang sama. Data b) mempunyai modus = 9, karena nilai observasi ini mempunyai frekuensi paling banyak. Data c) mempunyai dua modus yaitu 4 dan 7, dua nilai observasi tersebut mempunyai frekuensi palingbanyak dan sama banyak. Modus untuk data berkelompok Apabila data sudah dikelompokkan dan disajikan dalam tabel frekuensi, maka modusnya mempunyai rumus sebagai berikut: \u200b Kelas modus adalah kelas dimana terdapat nilai modus di dalamnya. Contoh: Hitunglah nilai modus dari data kelompok pada Tabel 1. solusi: Kelas modus adalah kelompok (60 \u2013 69), karena kelompok ini mempunyai frekuensi paling banyak. \u200b Ukuran dispersi Varians Dengan ukuran nilai tengah saja kita tidak akan pernah cukup untuk memberikan ringkasan karakteristik dari sebuah set data. Bagaimana sebaran observari dari nilai rata-ratanya? Apakah observasi mempunyai dispersi atau penyimpangan yang besar dari rata-ratanya? Kita biasanya memerlukan ukuran lainnya yaitu suatu ukuran tentang dispersi atau variasi didalam data. Pada kenyataannya nilai-nilai observasi suatu populasi ada yang lebih besar dari rata-rata dan ada yang lebih kecil dari rata. Informasi ini yang biasanya merupakan keterangan tambahan mengenai karakteristik dari satu set data yaitu informasi mengenai jumlah penyimpangan dalam data. Biasanya kita tertarik dengan penyimpangan nilai-nilai observasi dalam data terhadap rata-ratanya yaitu selisihnya. Rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan yang biasa disebut dengan varians dari observasi. Simbol varians pada ukuran populasi adalah (dibaca: sigma kuadrat) dan pada ukuran sampel adalah s 2 . Simpangan baku Akar dari varians dinamakan standar deviasi atau simpangan baku. Standar deviasi merupakan ukuran simpangan yang sering digunakan dalam analisa. Nilai standar deviasi pada dasarnya menggambarkan besaran sebaran suatu kelompok data terhadap rata-ratanya atau dengan kata lain gambaran keheterogenan suatu kelompok data. Formula standar deviasi adalah sebagai berikut: \u200b Contoh: jika kita gunakan data produksi 11 pohon pear, maka varians produksinya adalah: Dari hasil perhitungan didapat varians produksi dari 11 pohon pear adalah sebesar 2.575,2 kg. sehingga standar deviasi produksinya adalah sebesar 50,75 kg. katakan kita mempunyai data produksi (dalam kg) sebanyak 10 pohon pear dengan jenis yang berbeda dengan kelompok 11 pohon pear sebelumnya, yaitu: 230 475 366 268 136 330 326 402 215 492 kelompok ini mempunyai nilai rata-rata yang sama dengan kelompok 11 pohon pear sebelumnya yaitu sebasar 324 kg. Apakah dua kelompok pohon pear tersebut mempunyai kemampuan produksi yang sama? atau dengan kata lain kelompok pohon pear mana yang lebih konsisten dalam berproduksi? Jika harus memilih jenis pohon pear mana yang lebih konsisten berproduksi, maka kita akan memilih pohon pear pada kelompok yang mempunyai nilai varians terkecil (kelompok yang lebih homogen). Varians untuk data berkelompok Formula varians untuk data berkelompok adalah sebagai berikut: \u200b contoh: kita gunakan data nilai statistik 50 mahasiswa. Koefisien variasi Standar deviasi dapat mengukur keheterogenan atau variasi suatu kelompok data. Namun jika kita ingin membandingkan dua kelompok data yang mempunyai ukuran yang berbeda, standar deviasi tidak dapat digunakan artinya standar deviasi yang lebih besar tidak selalu berarti kelompok data tersebut lebih heterogen Untuk keperluan perbandingan dua kelompok data tanpa melihat ukuran satuannya, maka dapat digunakan suatu ukuran variasi yang dinamakan koefisien variasi (CV). Rumus CV dituliskan sebagai berikut: \u200b Jika CV1 > CV2 berarti kelompok data pertama lebih bervariasi atau lebih heterogen dari pada kelompok kedua. Ukuran nilai jarak (Range) Ukuran dispersi yang paling sederhana pada suatu data numerik mungkin dengan cara menghitung selisih nilai terbesar (nilai maksimum) dengan nilai terkecil (nilai minimum). Cara ini dikenal dengan sebutan Range . Range = Nilai maksimum \u2013 Nilai minimum. Range produksi 11 pohon pear = 402 \u2013 306 = 96 Ukuran Range untuk data berkelompok Untuk data berkelompok, nilai range dihitung berdasarkan selisih antara nilai tengah kelas terakhir dengan nilai tengah pertama atau selisih batas atas kelas terakhir dengan batas bawah kelas pertama. Range = Nilai tengah kelas terakhir \u2013 Nilai tengah kelas pertama. atau Range = Bonderi atas kelas terakhir \u2013 Bonderi bawah kelas pertama. dari data nilai statistik 50 mahasiswa pada tabel 1, nilai range nya adalah: Range = 94,5 \u2013 34,5 = 60 (cara ini cenderung menghilangkan nilai ekstrim). atau Range = 99,5 \u2013 29,5 = 70.","title":"Statistik Deskriptif"},{"location":"Tugas 1/#contoh-program","text":"File tambahannya lihat disini import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index ()","title":"Contoh Program"},{"location":"Tugas 1/#pustaka","text":"https://digensia.wordpress.com/2012/03/15/statistik-deskriptif/","title":"Pustaka"},{"location":"Tugas 2/","text":"Mengukur Jarak Data \u00b6 Mengukur Jarak Tipe Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan dimana m adalah bilangan riel positif dan x i dan y i adalah dua vektor dalam runang dimensi nn Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar. Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan Euclidean distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan dimana wi adalah bobot yang diberikan pada atribut ke i. Chord distance \u00b6 Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan dimana \u2016 x \u20162 adalah L 2-norm . Mahalanobis distance \u00b6 Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan dimana S adalah matrik covariance data. Cosine measure \u00b6 Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan dimana \u2225y\u22252 adalah Euclidean norm dari vektor y=(y1,y2,\u2026,yn)y=(y1,y2,\u2026,yn) didefinisikan dengan Pearson correlation \u00b6 Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan , where \u03bc x The Pearson correlation kelemahannya adalah sensitif terhadap outlier Mengukur Jarak Atribut Binary \u00b6 Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+tp=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama.Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antarii dan j adalah $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek ii dan jj dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$ Persamaan similarity ini disebut dengan Jaccard coefficient Mengukur Jarak Tipe categorical \u00b6 Li, C., & Li, H. (2010). A Survey of Distance Metrics for Nominal Attributes. JSW, 5(11), 1262-1269. Overlay Metric \u00b6 Ketika semua atribut adalah bertipe nominal, ukuran jarak yang paling sederhana adalah dengan Ovelay Metric (OM) yang dinyatakan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\delta ( a _ { i } ( x ) , a _ { i } ( y ) ) $$ dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing masing objek xx dan yy, \u03b4 (ai(x),ai(y))\u03b4 (ai(x),ai(y)) adalah 0 jika ai(x)=ai(y) dan 1 jika sebaliknya. OM banyak digunakan oleh instance-based learning dan locally weighted learning. Jelas sekali , ini sedikit beruk untuk mengukur jarak antara masing-masing pasangan sample, karena gagal memanfaatkan tambahan informasi yang diberikan oleh nilai atribut nominal yang bisa membantu dalam generalisasi. Value Difference Metric (VDM) \u00b6 VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\sum _ { c = 1 } ^ { C } \\left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \\right | $$ dimana CCadalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memiliki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas yy adalah cc dengan atribut AiAi memiliki nilai ai(y)ai(y) VDM mengasumsikan bahwa dua nilai dari atribut adalah lebih dekat jika memiliki klasifikasi sama. Pendekatan lain berbasi probabilitas adalah SFM (Short and Fukunaga Metric) yang kemudian dikembangkan oleh Myles dan Hand dan didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } \\left | P ( c | x ) - P ( c | y ) \\right| $$ diman probabilitas keanggotaan kelas diestimasi dengan P(c|x) dan P(c|y) didekati dengan Naive Bayes, Minimum Risk Metric (MRM) \u00b6 Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } P ( c | x ) ( 1 - P ( c | y ) ) $$ Mengukur Jarak Tipe Ordinal \u00b6 Han, J., Pei, J., & Kamber, M. (2011). Data mining: concepts and techniques. Elsevier . Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal ff yang memiliki MfMf state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius)dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 30, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. MM adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat 1,...,Mf1,...,Mf Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinal dari nn objek. Menghitung disimilarity terhadap f fitur sebagai berikut: Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan , mewakili peringkat 1,..,Mf1,..,Mf Ganti setiap xifxif dengan peringkatnya, rif\u2208{1...Mf}rif\u2208{1...Mf} Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi $ z _ { i f }$ Menghitung Jarak Tipe Campuran \u00b6 Wilson, D. R., & Martinez, T. R. (1997). Improved heterogeneous distance functions. Journal of artificial intelligence research, 6, 1-34. Menghitung ketidaksamaan antara objek dengan atribut campuran yang berupa nominal, biner simetris, biner asimetris, numerik, atau ordinal yang ada pada kebanyakan databasae dapat dinyatakan dengan memproses semua tipe atribut secara bersamaan. Salah satu teknik tersebut menggabungkan atribut yang berbeda ke dalam matriks ketidaksamaan tunggal dan menyatakannya dengan skala interval antar [0,0,1.0][0,0,1.0]. Misalkan data berisi atribut pp tipe campuran. Ketidaksamaan (disimilarity ) antara objek ii dan jj dinyatakan dengan $$ d ( i , j ) = \\frac { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } } $$ dimana \u03b4fij=0\u03b4ijf=0 - jika xifxif atau xjfxjf adalah hilang (i.e., tidak ada pengukuran dari atribut f untuk objek ii atau objek jj) jika xif=xjf=0xif=xjf=0 dan atribut ff adalah binary asymmetric, selain itu \u03b4fij=1\u03b4ijf=1 Kontribusi dari atribut ff untuk dissimilarity antara i dan j (yaitu.dfijdijf) dihitung bergantung pada tipenya, Jika ff adalah numerik, $$ d_{ij}^{f}=\\frac{ |x {if}-x {jf}|}{max_hx_{hf}-min_hx{hf}} $$ , di mana h menjalankan semua nilai objek yang tidak hilang untuk atribut f Jika ff adalah nominal atau binary,$d_{ij}^{f}=0 $jika xif=xjfxif=xjf, sebaliknya dfij=1dijf=1 Jika ff adalah ordinal maka hitung rangking rifrif dan $$ \\mathcal z_{if}=\\frac {r_{if}-1}{M_f-1} $$ , dan perlakukan zifzif sebagai numerik.","title":"Mengukur Jarak"},{"location":"Tugas 2/#mengukur-jarak-data","text":"","title":"Mengukur Jarak Data"},{"location":"Tugas 2/#mengukur-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya","title":"Mengukur Jarak Tipe Numerik"},{"location":"Tugas 2/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan dimana m adalah bilangan riel positif dan x i dan y i adalah dua vektor dalam runang dimensi nn Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar.","title":"Minkowski Distance"},{"location":"Tugas 2/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan","title":"Manhattan distance"},{"location":"Tugas 2/#euclidean-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini.","title":"Euclidean distance"},{"location":"Tugas 2/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan","title":"Average Distance"},{"location":"Tugas 2/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan dimana wi adalah bobot yang diberikan pada atribut ke i.","title":"Weighted euclidean distance"},{"location":"Tugas 2/#chord-distance","text":"Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan dimana \u2016 x \u20162 adalah L 2-norm .","title":"Chord distance"},{"location":"Tugas 2/#mahalanobis-distance","text":"Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan dimana S adalah matrik covariance data.","title":"Mahalanobis distance"},{"location":"Tugas 2/#cosine-measure","text":"Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan dimana \u2225y\u22252 adalah Euclidean norm dari vektor y=(y1,y2,\u2026,yn)y=(y1,y2,\u2026,yn) didefinisikan dengan","title":"Cosine measure"},{"location":"Tugas 2/#pearson-correlation","text":"Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan , where \u03bc x The Pearson correlation kelemahannya adalah sensitif terhadap outlier","title":"Pearson correlation"},{"location":"Tugas 2/#mengukur-jarak-atribut-binary","text":"Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+tp=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama.Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antarii dan j adalah $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek ii dan jj dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$ Persamaan similarity ini disebut dengan Jaccard coefficient","title":"Mengukur Jarak Atribut Binary"},{"location":"Tugas 2/#mengukur-jarak-tipe-categorical","text":"Li, C., & Li, H. (2010). A Survey of Distance Metrics for Nominal Attributes. JSW, 5(11), 1262-1269.","title":"Mengukur Jarak Tipe categorical"},{"location":"Tugas 2/#overlay-metric","text":"Ketika semua atribut adalah bertipe nominal, ukuran jarak yang paling sederhana adalah dengan Ovelay Metric (OM) yang dinyatakan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\delta ( a _ { i } ( x ) , a _ { i } ( y ) ) $$ dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing masing objek xx dan yy, \u03b4 (ai(x),ai(y))\u03b4 (ai(x),ai(y)) adalah 0 jika ai(x)=ai(y) dan 1 jika sebaliknya. OM banyak digunakan oleh instance-based learning dan locally weighted learning. Jelas sekali , ini sedikit beruk untuk mengukur jarak antara masing-masing pasangan sample, karena gagal memanfaatkan tambahan informasi yang diberikan oleh nilai atribut nominal yang bisa membantu dalam generalisasi.","title":"Overlay Metric"},{"location":"Tugas 2/#value-difference-metric-vdm","text":"VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\sum _ { c = 1 } ^ { C } \\left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \\right | $$ dimana CCadalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memiliki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas yy adalah cc dengan atribut AiAi memiliki nilai ai(y)ai(y) VDM mengasumsikan bahwa dua nilai dari atribut adalah lebih dekat jika memiliki klasifikasi sama. Pendekatan lain berbasi probabilitas adalah SFM (Short and Fukunaga Metric) yang kemudian dikembangkan oleh Myles dan Hand dan didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } \\left | P ( c | x ) - P ( c | y ) \\right| $$ diman probabilitas keanggotaan kelas diestimasi dengan P(c|x) dan P(c|y) didekati dengan Naive Bayes,","title":"Value Difference Metric (VDM)"},{"location":"Tugas 2/#minimum-risk-metric-mrm","text":"Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } P ( c | x ) ( 1 - P ( c | y ) ) $$","title":"Minimum Risk Metric (MRM)"},{"location":"Tugas 2/#mengukur-jarak-tipe-ordinal","text":"Han, J., Pei, J., & Kamber, M. (2011). Data mining: concepts and techniques. Elsevier . Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal ff yang memiliki MfMf state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius)dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 30, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. MM adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat 1,...,Mf1,...,Mf Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinal dari nn objek. Menghitung disimilarity terhadap f fitur sebagai berikut: Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan , mewakili peringkat 1,..,Mf1,..,Mf Ganti setiap xifxif dengan peringkatnya, rif\u2208{1...Mf}rif\u2208{1...Mf} Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi $ z _ { i f }$","title":"Mengukur Jarak Tipe Ordinal"},{"location":"Tugas 2/#menghitung-jarak-tipe-campuran","text":"Wilson, D. R., & Martinez, T. R. (1997). Improved heterogeneous distance functions. Journal of artificial intelligence research, 6, 1-34. Menghitung ketidaksamaan antara objek dengan atribut campuran yang berupa nominal, biner simetris, biner asimetris, numerik, atau ordinal yang ada pada kebanyakan databasae dapat dinyatakan dengan memproses semua tipe atribut secara bersamaan. Salah satu teknik tersebut menggabungkan atribut yang berbeda ke dalam matriks ketidaksamaan tunggal dan menyatakannya dengan skala interval antar [0,0,1.0][0,0,1.0]. Misalkan data berisi atribut pp tipe campuran. Ketidaksamaan (disimilarity ) antara objek ii dan jj dinyatakan dengan $$ d ( i , j ) = \\frac { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } } $$ dimana \u03b4fij=0\u03b4ijf=0 - jika xifxif atau xjfxjf adalah hilang (i.e., tidak ada pengukuran dari atribut f untuk objek ii atau objek jj) jika xif=xjf=0xif=xjf=0 dan atribut ff adalah binary asymmetric, selain itu \u03b4fij=1\u03b4ijf=1 Kontribusi dari atribut ff untuk dissimilarity antara i dan j (yaitu.dfijdijf) dihitung bergantung pada tipenya, Jika ff adalah numerik, $$ d_{ij}^{f}=\\frac{ |x {if}-x {jf}|}{max_hx_{hf}-min_hx{hf}} $$ , di mana h menjalankan semua nilai objek yang tidak hilang untuk atribut f Jika ff adalah nominal atau binary,$d_{ij}^{f}=0 $jika xif=xjfxif=xjf, sebaliknya dfij=1dijf=1 Jika ff adalah ordinal maka hitung rangking rifrif dan $$ \\mathcal z_{if}=\\frac {r_{if}-1}{M_f-1} $$ , dan perlakukan zifzif sebagai numerik.","title":"Menghitung Jarak Tipe Campuran"}]}